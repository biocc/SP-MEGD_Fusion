{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efd8076e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 结果已保存到: E:\\Data\\stitch-v1.4.0-windows\\results\\SA58\\template_search.csv\n",
      "Runname: SA58\n",
      "heavy.V: IGHV7-4-1 | len=98 | preview=QVQLVQSGSELKKPGASVKVSCKASGYTFTSYAMNWVRQAPGQGLEWMGWINTNTGNPTYAQGFTGRFVFSLDTSVSTAYLQICSLKAEDTAVYYCAR\n",
      "heavy.J: IGHJ4 | len=15 | preview=YFDYWGQGTLVTVSS\n",
      "heavy.C: IGHG1 | len=330 | preview=ASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKVEPKSCDKTHTCPPCPAPELLGGPSVFLFPPKPKDTLMISRTPEVTCVVVDVSHEDPEVKFNWYVDGVEVHNAKTKPREEQYNSTYRVVSVLTVLHQDWLNGKEYKCKVSNKALPAPIEKTISKAKGQPREPQVYTLPPSRDELTKNQVSLTCLVKGFYPSDIAVEWESNGQPENNYKTTPPVLDSDGSFFLYSKLTVDKSRWQQGNVFSCSVMHEALHNHYTQKSLSLSPGK\n",
      "light.V: IGKV3-15 | len=95 | preview=EIVMTQSPATLSVSPGERATLSCRASQSVSSNLAWYQQKPGQAPRLLIYGASTRATGIPARFSGSGSGTEFTLTISSLQSEDFAVYYCQQYNNWP\n",
      "light.J: IGKJ4 | len=12 | preview=LTFGGGTKVEIK\n",
      "light.C: IGKC | len=107 | preview=RTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRGEC\n",
      "\n",
      "=== HEAVY ===\n",
      "- CDR1:\n",
      "  ranges: [(25, 32)]\n",
      "  sequence (8 aa): GYTFTSYA\n",
      "  preceding7 (18..24): KVSCKAS\n",
      "  preceding7 labels: ['Variable', 'Variable', 'Variable', 'Conserved', 'Variable', 'Variable', 'Variable']\n",
      "  following7 (33..39): MNWVRQA\n",
      "  following7 labels: ['Variable', 'Variable', 'Conserved', 'Variable', 'Variable', 'Variable', 'Variable']\n",
      "- CDR2:\n",
      "  ranges: [(50, 57)]\n",
      "  sequence (8 aa): INTNTGNP\n",
      "  preceding7 (43..49): GLEWMGW\n",
      "  preceding7 labels: ['Variable', 'Variable', 'Variable', 'Variable', 'Variable', 'Variable', 'Variable']\n",
      "  following7 (58..64): TYAQGFT\n",
      "  following7 labels: ['Variable', 'Variable', 'Variable', 'Variable', 'Variable', 'Variable', 'Variable']\n",
      "- CDR3:\n",
      "  ranges: [(96, 101)]\n",
      "  sequence (6 aa): ARYFDY\n",
      "  preceding7 (89..95): DTAVYYC\n",
      "  preceding7 labels: ['Variable', 'Variable', 'Variable', 'Variable', 'Variable', 'Variable', 'Conserved']\n",
      "  following7 (102..108): WGQGTLV\n",
      "  following7 labels: ['Conserved', 'Conserved', 'Variable', 'Conserved', 'Variable', 'Variable', 'Variable']\n",
      "\n",
      "=== LIGHT ===\n",
      "- CDR1:\n",
      "  ranges: [(26, 31)]\n",
      "  sequence (6 aa): QSVSSN\n",
      "  preceding7 (19..25): TLSCRAS\n",
      "  preceding7 labels: ['Variable', 'Variable', 'Variable', 'Conserved', 'Variable', 'Variable', 'Variable']\n",
      "  following7 (32..38): LAWYQQK\n",
      "  following7 labels: ['Variable', 'Variable', 'Conserved', 'Variable', 'Variable', 'Variable', 'Variable']\n",
      "- CDR2:\n",
      "  ranges: [(49, 51)]\n",
      "  sequence (3 aa): GAS\n",
      "  preceding7 (42..48): APRLLIY\n",
      "  preceding7 labels: ['Variable', 'Variable', 'Variable', 'Variable', 'Variable', 'Variable', 'Variable']\n",
      "  following7 (52..58): TRATGIP\n",
      "  following7 labels: ['Variable', 'Variable', 'Variable', 'Variable', 'Variable', 'Variable', 'Variable']\n",
      "- CDR3:\n",
      "  ranges: [(88, 96)]\n",
      "  sequence (9 aa): QQYNNWPLT\n",
      "  preceding7 (81..87): DFAVYYC\n",
      "  preceding7 labels: ['Variable', 'Variable', 'Variable', 'Variable', 'Variable', 'Variable', 'Conserved']\n",
      "  following7 (97..103): FGGGTKV\n",
      "  following7 labels: ['Conserved', 'Conserved', 'Variable', 'Conserved', 'Variable', 'Variable', 'Variable']\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "import pandas as pd\n",
    "\n",
    "# ===================== Ⅰ. 从 FASTA 提取每类最高分 template =====================\n",
    "\n",
    "def classify_template(name: str) -> str:\n",
    "    \"\"\"按模板名前缀归类为 HV/HJ/HC/LV/LJ/LC/Unknown。\"\"\"\n",
    "    if name.startswith(\"IGHV\"):\n",
    "        return \"HV\"\n",
    "    elif name.startswith(\"IGHJ\"):\n",
    "        return \"HJ\"\n",
    "    elif name.startswith(\"IGH\"):\n",
    "        return \"HC\"\n",
    "    elif name.startswith(\"IGKV\") or name.startswith(\"IGLV\"):\n",
    "        return \"LV\"\n",
    "    elif name.startswith(\"IGKJ\") or name.startswith(\"IGLJ\"):\n",
    "        return \"LJ\"\n",
    "    elif name.startswith(\"IGKC\") or name.startswith(\"IGLC\"):\n",
    "        return \"LC\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "def extract_template_info_from_fasta(fasta_path: str, output_csv_path: Optional[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    从 .fasta 的 header 提取 template 名、score 与类型(type)。\n",
    "    期望 header 形如：\">IGHV1-46 ... score:123 ...\"\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    with open(fasta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if not line.startswith(\">\"):\n",
    "                continue\n",
    "            header = line[1:].strip()\n",
    "            parts = header.split()\n",
    "            template = parts[0]\n",
    "            score = None\n",
    "            for p in parts:\n",
    "                if p.startswith(\"score:\"):\n",
    "                    try:\n",
    "                        score = int(p.split(\":\", 1)[1])\n",
    "                    except ValueError:\n",
    "                        score = None\n",
    "                    break\n",
    "            records.append({\"template\": template, \"type\": classify_template(template), \"score\": score})\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    if output_csv_path:\n",
    "        df.to_csv(output_csv_path, index=False)\n",
    "        print(f\"✅ 结果已保存到: {output_csv_path}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ===================== Ⅱ. 解析 Stitch 配置 & 读取六段序列 =====================\n",
    "\n",
    "def parse_stitch_config_segments(cfg_path: str) -> Tuple[Dict[str, Dict[str, str]], str]:\n",
    "    \"\"\"\n",
    "    返回:\n",
    "      segments: {'heavy': {'V','J','C'}, 'light': {'V','J','C'}}  -> 对应的 fasta 路径\n",
    "      runname : 例如 '50ugS2P6'\n",
    "    \"\"\"\n",
    "    segments = {'heavy': {'V': None, 'J': None, 'C': None},\n",
    "                'light': {'V': None, 'J': None, 'C': None}}\n",
    "\n",
    "    current_chain: Optional[str] = None\n",
    "    in_segment = False\n",
    "    seg_name = None\n",
    "    seg_path = None\n",
    "\n",
    "    name_re = re.compile(r'^\\s*Name\\s*:\\s*(\\S+)\\s*$', re.IGNORECASE)\n",
    "    path_re = re.compile(r'^\\s*Path\\s*:\\s*(.+?\\.(?:fa|fasta|faa|fna))\\s*$', re.IGNORECASE)\n",
    "    run_re  = re.compile(r'^\\s*Runname\\s*:\\s*(.+?)\\s*$', re.IGNORECASE)\n",
    "\n",
    "    runname: Optional[str] = None\n",
    "\n",
    "    def commit():\n",
    "        nonlocal seg_name, seg_path\n",
    "        if not (current_chain and seg_name and seg_path):\n",
    "            return\n",
    "        n = seg_name.upper().strip().strip('\"').strip(\"'\")\n",
    "        p = seg_path.strip().strip('\"').strip(\"'\")\n",
    "        if current_chain == 'heavy':\n",
    "            if n == 'IGHV': segments['heavy']['V'] = p\n",
    "            elif n == 'IGHJ': segments['heavy']['J'] = p\n",
    "            elif n == 'IGHC': segments['heavy']['C'] = p\n",
    "        elif current_chain == 'light':\n",
    "            if n in ('IGLV', 'IGKV'): segments['light']['V'] = p\n",
    "            elif n in ('IGLJ', 'IGKJ'): segments['light']['J'] = p\n",
    "            elif n in ('IGLC', 'IGKC'): segments['light']['C'] = p\n",
    "\n",
    "    with open(cfg_path, 'r', encoding='utf-8') as f:\n",
    "        for raw in f:\n",
    "            # Runname 可在文件任意处\n",
    "            if runname is None:\n",
    "                m_run = run_re.match(raw)\n",
    "                if m_run:\n",
    "                    runname = m_run.group(1).strip().strip('\"').strip(\"'\")\n",
    "\n",
    "            line = raw.strip()\n",
    "\n",
    "            if line.startswith('Heavy Chain->'):\n",
    "                current_chain = 'heavy'; in_segment = False; seg_name = seg_path = None; continue\n",
    "            if line.startswith('Light Chain->'):\n",
    "                current_chain = 'light'; in_segment = False; seg_name = seg_path = None; continue\n",
    "\n",
    "            if line.startswith('Segment->'):\n",
    "                in_segment = True; seg_name = seg_path = None; continue\n",
    "            if line == '<-':\n",
    "                if in_segment: commit()\n",
    "                in_segment = False; seg_name = seg_path = None; continue\n",
    "\n",
    "            if not in_segment or current_chain not in ('heavy', 'light'):\n",
    "                continue\n",
    "\n",
    "            m_path = path_re.match(raw)\n",
    "            if m_path:\n",
    "                seg_path = m_path.group(1); commit(); continue\n",
    "            m_name = name_re.match(raw)\n",
    "            if m_name:\n",
    "                seg_name = m_name.group(1); commit(); continue\n",
    "\n",
    "    if in_segment:\n",
    "        commit()\n",
    "\n",
    "    missing = [(ch, rgn) for ch in ('heavy', 'light') for rgn in ('V','J','C') if not segments[ch][rgn]]\n",
    "    if missing:\n",
    "        raise ValueError(f\"以下槽位未解析到 FASTA 路径: {missing}\")\n",
    "    if not runname:\n",
    "        raise ValueError(\"Runname 未找到，请检查配置文件。\")\n",
    "\n",
    "    return segments, runname\n",
    "\n",
    "\n",
    "def load_annotated_fasta(path: str, key_mode: str = \"first_token\") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    读取带注释 FASTA，返回 {id: 单行文本}。\n",
    "    关键点：每行先 strip()，再用 ''.join(buf) 无分隔符拼接，避免跨行插入空格；\n",
    "           同时移除 NBSP（\\xa0）。\n",
    "    \"\"\"\n",
    "    records: Dict[str, str] = {}\n",
    "    cur_key: Optional[str] = None\n",
    "    buf: List[str] = []\n",
    "\n",
    "    def _push():\n",
    "        if cur_key is not None:\n",
    "            raw = \"\".join(buf).replace(\"\\xa0\", \" \")\n",
    "            records[cur_key] = raw\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\">\"):\n",
    "                _push()\n",
    "                head = line[1:].strip()\n",
    "                key = head.split()[0] if key_mode == \"first_token\" else head\n",
    "                cur_key = key\n",
    "                buf = []\n",
    "            else:\n",
    "                buf.append(line.strip())\n",
    "    _push()\n",
    "    return records\n",
    "\n",
    "def extract_sequence_by_id(fasta_path: str, target_id: str, key_mode: str = \"first_token\") -> str:\n",
    "    db = load_annotated_fasta(fasta_path, key_mode=key_mode)\n",
    "    lut = {k.upper(): k for k in db.keys()}\n",
    "    k = lut.get(target_id.upper())\n",
    "    if k is None:\n",
    "        raise KeyError(f\"ID '{target_id}' not found in {fasta_path}\")\n",
    "    return db[k]\n",
    "\n",
    "\n",
    "# ---- 模板解析（V/J/C） ----\n",
    "\n",
    "def _ctx(seq: str, i: int, span: int = 25) -> str:\n",
    "    s = max(0, i - span); e = min(len(seq), i + span)\n",
    "    return seq[s:e]\n",
    "\n",
    "def _parse_template_with_rules(seq: str, default_label: str, allowed_cdr: List[str]) -> Tuple[str, List[str]]:\n",
    "    \"\"\"\n",
    "    严格模式解析：\n",
    "      - 仅识别 (Conserved X...) 和 (CDR1/2/3 Y...) 两类括号标注；\n",
    "      - 括号外仅允许 A-Z；\n",
    "      - 未闭合/未知括号或非法字符会抛错（包含上下文）。\n",
    "    \"\"\"\n",
    "    pure: List[str] = []\n",
    "    labels: List[str] = []\n",
    "    i, n = 0, len(seq)\n",
    "\n",
    "    while i < n:\n",
    "        ch = seq[i]\n",
    "        if ch == '(':\n",
    "            j = seq.find(')', i + 1)\n",
    "            if j == -1:\n",
    "                raise ValueError(f\"未闭合的 '(' (pos={i}). context='{_ctx(seq, i)}'\")\n",
    "\n",
    "            token = seq[i+1:j]\n",
    "            token_norm = re.sub(r\"\\s+\", \" \", token.strip())\n",
    "\n",
    "            if token_norm.startswith(\"Conserved\"):\n",
    "                aa_block = re.sub(r'[^A-Z]', '', token_norm[len(\"Conserved\"):])\n",
    "                if not aa_block:\n",
    "                    raise ValueError(f\"(Conserved ...) 中未检测到氨基酸 (pos={i}). token='{token_norm}'\")\n",
    "                for aa in aa_block:\n",
    "                    pure.append(aa); labels.append(\"Conserved\")\n",
    "                i = j + 1; continue\n",
    "\n",
    "            if token_norm.startswith(\"CDR\"):\n",
    "                m = re.match(r\"^CDR\\s*([1-3])\\s*([A-Za-z\\s]*)$\", token_norm)\n",
    "                if not m:\n",
    "                    raise ValueError(f\"无法解析的 CDR 标注 (pos={i}). token='{token_norm}'\")\n",
    "                cdr_tag = f\"CDR{m.group(1)}\"\n",
    "                aa_block = re.sub(r'[^A-Z]', '', m.group(2))\n",
    "                if not aa_block:\n",
    "                    raise ValueError(f\"{cdr_tag} 中未检测到氨基酸 (pos={i}). token='{token_norm}'\")\n",
    "                tag = cdr_tag if cdr_tag in allowed_cdr else default_label\n",
    "                for aa in aa_block:\n",
    "                    pure.append(aa); labels.append(tag)\n",
    "                i = j + 1; continue\n",
    "\n",
    "            # 其它括号内容：严格报错\n",
    "            raise ValueError(f\"未知括号标注 (pos={i}). token='{token_norm}'. context='{_ctx(seq, i)}'\")\n",
    "\n",
    "        # 括号外：此时无跨行空格，仅允许 A–Z\n",
    "        if 'A' <= ch <= 'Z':\n",
    "            pure.append(ch); labels.append(default_label); i += 1; continue\n",
    "\n",
    "        raise ValueError(f\"非法字符 '{ch}' (pos={i}). context='{_ctx(seq, i)}'\")\n",
    "\n",
    "    if len(pure) != len(labels):\n",
    "        raise RuntimeError(\"解析后序列与标签长度不一致\")\n",
    "    return \"\".join(pure), labels\n",
    "\n",
    "def parse_v_template_to_labels(seq: str) -> Tuple[str, List[str]]:\n",
    "    return _parse_template_with_rules(seq, \"Variable\", [\"CDR1\",\"CDR2\",\"CDR3\"])\n",
    "\n",
    "def parse_j_template_to_labels(seq: str) -> Tuple[str, List[str]]:\n",
    "    return _parse_template_with_rules(seq, \"Variable\", [\"CDR3\"])\n",
    "\n",
    "def parse_c_template_to_labels(seq: str) -> Tuple[str, List[str]]:\n",
    "    return _parse_template_with_rules(seq, \"Constant\", [])\n",
    "\n",
    "\n",
    "def get_six_segments(cfg_path: str,\n",
    "                     target_ids: Dict[str, Dict[str, str]],\n",
    "                     key_mode: str = \"first_token\") -> Tuple[Dict[str, Dict[str, Tuple[str, List[str]]]], str]:\n",
    "    \"\"\"根据 six IDs 读取六段并解析，返回 (six_segments, runname)。\"\"\"\n",
    "    seg_paths, runname = parse_stitch_config_segments(cfg_path)\n",
    "    out: Dict[str, Dict[str, Tuple[str, List[str]]]] = {'heavy': {}, 'light': {}}\n",
    "\n",
    "    for chain in ('heavy', 'light'):\n",
    "        for region in ('V', 'J', 'C'):\n",
    "            fasta_path = seg_paths[chain][region]\n",
    "            tid = target_ids[chain][region]\n",
    "            annotated = extract_sequence_by_id(fasta_path, tid, key_mode=key_mode)\n",
    "\n",
    "            if region == 'V':\n",
    "                seq, labels = parse_v_template_to_labels(annotated)\n",
    "            elif region == 'J':\n",
    "                seq, labels = parse_j_template_to_labels(annotated)\n",
    "            else:\n",
    "                seq, labels = parse_c_template_to_labels(annotated)\n",
    "\n",
    "            out[chain][region] = (seq, labels)\n",
    "    return out, runname\n",
    "\n",
    "\n",
    "# ===================== Ⅲ. 拼接整链并提取 CDR & 前/后7 =====================\n",
    "\n",
    "def _concat_chain(segments: Dict[str, Tuple[str, List[str]]]) -> Tuple[str, List[str]]:\n",
    "    \"\"\"\n",
    "    将 V/J/C 三段顺序拼接为一条链，并合并标签。\n",
    "    segments: {'V': (seq, labels), 'J': (seq, labels), 'C': (seq, labels)}\n",
    "    \"\"\"\n",
    "    full_seq_parts: List[str] = []\n",
    "    full_labels: List[str] = []\n",
    "    for r in (\"V\", \"J\", \"C\"):\n",
    "        seq, lab = segments[r]\n",
    "        if len(seq) != len(lab):\n",
    "            raise RuntimeError(f\"{r} 段序列与标签长度不一致\")\n",
    "        full_seq_parts.append(seq)\n",
    "        full_labels.extend(lab)\n",
    "    return \"\".join(full_seq_parts), full_labels\n",
    "\n",
    "def _contiguous_ranges(labels: List[str], target: str) -> List[Tuple[int, int]]:\n",
    "    \"\"\"在整条链的标签序列中，找到等于 target 的所有连续区间 [start, end]（闭区间）。\"\"\"\n",
    "    ranges: List[Tuple[int, int]] = []\n",
    "    start: Optional[int] = None\n",
    "    for i, lab in enumerate(labels):\n",
    "        if lab == target:\n",
    "            if start is None:\n",
    "                start = i\n",
    "        else:\n",
    "            if start is not None:\n",
    "                ranges.append((start, i - 1))\n",
    "                start = None\n",
    "    if start is not None:\n",
    "        ranges.append((start, len(labels) - 1))\n",
    "    return ranges\n",
    "\n",
    "def _slice_seq_labels(seq: str, labels: List[str], s: int, e: int) -> Tuple[str, List[str]]:\n",
    "    if s > e:\n",
    "        return \"\", []\n",
    "    return seq[s:e+1], labels[s:e+1]\n",
    "\n",
    "def _preceding_k(seq: str, labels: List[str], start_idx: int, k: int = 7) -> Tuple[str, List[str], Tuple[int, int]]:\n",
    "    \"\"\"返回 start_idx 之前连续 k 个氨基酸（不够就尽量），及其标签与闭区间 (s,e)。\"\"\"\n",
    "    if start_idx <= 0:\n",
    "        return \"\", [], (-1, -1)\n",
    "    s = max(0, start_idx - k)\n",
    "    e = start_idx - 1\n",
    "    frag_seq, frag_lab = _slice_seq_labels(seq, labels, s, e)\n",
    "    return frag_seq, frag_lab, (s, e)\n",
    "\n",
    "def _following_k(seq: str, labels: List[str], end_idx: int, k: int = 7) -> Tuple[str, List[str], Tuple[int, int]]:\n",
    "    \"\"\"返回 end_idx 之后连续 k 个氨基酸（不够就尽量），及其标签与闭区间 (s,e)。\"\"\"\n",
    "    n = len(seq)\n",
    "    if end_idx >= n - 1:\n",
    "        return \"\", [], (-1, -1)\n",
    "    s = end_idx + 1\n",
    "    e = min(n - 1, end_idx + k)\n",
    "    frag_seq, frag_lab = _slice_seq_labels(seq, labels, s, e)\n",
    "    return frag_seq, frag_lab, (s, e)\n",
    "\n",
    "def extract_cdr_and_flanks(\n",
    "    six_segments: Dict[str, Dict[str, Tuple[str, List[str]]]],\n",
    "    k: int = 7\n",
    ") -> Dict[str, Dict[str, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    提取 Heavy/Light 的 CDR1/2/3 序列、ranges、以及前/后 k 个氨基酸（序列+标签+位置）。\n",
    "    返回结构:\n",
    "      result[chain][cdr] = {\n",
    "        \"sequence\": str,\n",
    "        \"ranges\": List[(s,e)],\n",
    "        \"preceding7_seq\": str, \"preceding7_labels\": List[str], \"preceding7_range\": (s,e),\n",
    "        \"following7_seq\": str, \"following7_labels\": List[str], \"following7_range\": (s,e),\n",
    "      }\n",
    "    \"\"\"\n",
    "    result: Dict[str, Dict[str, Dict[str, Any]]] = {}\n",
    "    for chain in (\"heavy\", \"light\"):\n",
    "        full_seq, full_labels = _concat_chain(six_segments[chain])\n",
    "        chain_out: Dict[str, Dict[str, Any]] = {}\n",
    "        for cdr_tag in (\"CDR1\", \"CDR2\", \"CDR3\"):\n",
    "            ranges = _contiguous_ranges(full_labels, cdr_tag)\n",
    "            cdr_seq = \"\".join(full_seq[s:e+1] for s, e in ranges) if ranges else \"\"\n",
    "\n",
    "            if ranges:\n",
    "                first_start = ranges[0][0]\n",
    "                last_end = ranges[-1][1]\n",
    "                pre_seq, pre_lab, pre_rng = _preceding_k(full_seq, full_labels, first_start, k=k)\n",
    "                fol_seq, fol_lab, fol_rng = _following_k(full_seq, full_labels, last_end, k=k)\n",
    "            else:\n",
    "                pre_seq, pre_lab, pre_rng = \"\", [], (-1, -1)\n",
    "                fol_seq, fol_lab, fol_rng = \"\", [], (-1, -1)\n",
    "\n",
    "            chain_out[cdr_tag] = {\n",
    "                \"sequence\": cdr_seq,\n",
    "                \"ranges\": ranges,\n",
    "                \"preceding7_seq\": pre_seq,\n",
    "                \"preceding7_labels\": pre_lab,\n",
    "                \"preceding7_range\": pre_rng,\n",
    "                \"following7_seq\": fol_seq,\n",
    "                \"following7_labels\": fol_lab,\n",
    "                \"following7_range\": fol_rng,\n",
    "            }\n",
    "        result[chain] = chain_out\n",
    "    return result\n",
    "\n",
    "def _pretty_print_cdr(info: Dict[str, Dict[str, Dict[str, Any]]], k: int = 7) -> None:\n",
    "    for chain in (\"heavy\", \"light\"):\n",
    "        print(f\"\\n=== {chain.UPPER()} ===\" if hasattr(chain, \"UPPER\") else f\"\\n=== {chain.upper()} ===\")\n",
    "        for cdr in (\"CDR1\", \"CDR2\", \"CDR3\"):\n",
    "            item = info[chain][cdr]\n",
    "            seq = item[\"sequence\"]\n",
    "            ranges = item[\"ranges\"]\n",
    "            pre7 = item[\"preceding7_seq\"]; pre7_labels = item[\"preceding7_labels\"]; ps, pe = item[\"preceding7_range\"]\n",
    "            fol7 = item[\"following7_seq\"];  fol7_labels = item[\"following7_labels\"]; fs, fe = item[\"following7_range\"]\n",
    "            print(f\"- {cdr}:\")\n",
    "            print(f\"  ranges: {ranges if ranges else '[]'}\")\n",
    "            print(f\"  sequence ({len(seq)} aa): {seq if seq else 'N/A'}\")\n",
    "            print(f\"  preceding{k} ({ps}..{pe}): {pre7 if pre7 else 'N/A'}\")\n",
    "            if pre7_labels: print(f\"  preceding{k} labels: {pre7_labels}\")\n",
    "            print(f\"  following{k} ({fs}..{fe}): {fol7 if fol7 else 'N/A'}\")\n",
    "            if fol7_labels: print(f\"  following{k} labels: {fol7_labels}\")\n",
    "\n",
    "\n",
    "# ===================== Ⅳ. 使用示例（main） =====================\n",
    "if __name__ == \"__main__\":\n",
    "    # A) 从 tm.fasta 得到每类(type)最高分的 template 名\n",
    "    fasta_file = r\"E:\\Data\\stitch-v1.4.0-windows\\results\\SA58\\report-monoclonal-tm.fasta\"\n",
    "    output_csv = r\"E:\\Data\\stitch-v1.4.0-windows\\results\\SA58\\template_search.csv\"\n",
    "    df = extract_template_info_from_fasta(fasta_file, output_csv_path=output_csv)\n",
    "\n",
    "    # 分组取最大分\n",
    "    best_template_name = (df.loc[df.groupby(\"type\")[\"score\"].idxmax()]\n",
    "                            .set_index(\"type\")[\"template\"]\n",
    "                            .to_dict())\n",
    "\n",
    "    # B) 配置文件\n",
    "    cfg_path = r\"E:\\Data\\stitch-v1.4.0-windows\\batchfiles\\SA58.txt\"\n",
    "\n",
    "    # C) 用最佳模板名拼成 six IDs\n",
    "    required = [\"HV\",\"HJ\",\"HC\",\"LV\",\"LJ\",\"LC\"]\n",
    "    miss = [k for k in required if k not in best_template_name or not best_template_name[k]]\n",
    "    if miss:\n",
    "        raise ValueError(f\"从 {fasta_file} 提取的 best_template_name 缺少：{miss}\")\n",
    "\n",
    "    target_ids = {\n",
    "        \"heavy\": {\"V\": best_template_name[\"HV\"], \"J\": best_template_name[\"HJ\"], \"C\": best_template_name[\"HC\"]},\n",
    "        \"light\": {\"V\": best_template_name[\"LV\"], \"J\": best_template_name[\"LJ\"], \"C\": best_template_name[\"LC\"]},\n",
    "    }\n",
    "\n",
    "    # D) 读取并解析六段\n",
    "    template, runname = get_six_segments(cfg_path, target_ids)\n",
    "    print(\"Runname:\", runname)\n",
    "    for chain in (\"heavy\", \"light\"):\n",
    "        for region in (\"V\", \"J\", \"C\"):\n",
    "            seq, labels = template[chain][region]\n",
    "            print(f\"{chain}.{region}: {target_ids[chain][region]} | len={len(seq)} | preview={seq}\")\n",
    "\n",
    "    # E) 提取 Heavy/Light 的 CDR1/2/3 以及前/后 7 位（序列+标签）\n",
    "    cdr_info = extract_cdr_and_flanks(template, k=7)\n",
    "    _pretty_print_cdr(cdr_info, k=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c2fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import heapq\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "def read_kmer_set_from_csv(file_path):\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(file_path)\n",
    "    # 过滤长度为7的kmer并转换为字典\n",
    "    kmer_set = {kmer: count for kmer, count in zip(df['kmer'], df['count']) if len(kmer) == 7}\n",
    "    return kmer_set\n",
    "\n",
    "def beam_search(start_kmer: str,\n",
    "                start_kmer_template: Optional[str],\n",
    "                kmers: Dict[str, int],\n",
    "                template_sequence: str,\n",
    "                template_labels: List[str],\n",
    "                beam_width: int,\n",
    "                max_iterations: int,\n",
    "                top_n: int = 3,\n",
    "                dist_threshold: int = 5,\n",
    "                cdr_tail: int = 6,\n",
    "                stop_sequence: Optional[str] = None,\n",
    "                direction: int = 1,\n",
    "                distance_guard: int = 1,                   # 1=启用距离保护, -1=关闭\n",
    "                ban_sequences: Optional[List[str]] = None, # 长序列黑名单：I→L，再生成所有7-mer\n",
    "                template_weight_mode: int = 1              # 1=按模板加权；-1=仅用count，不加权\n",
    "                ) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    固定 7-mer 的束搜索（自动起点定位 + 双向扩展）\n",
    "\n",
    "    新增：template_weight_mode\n",
    "      - 1 : 模板匹配加权（保守位点×10，非保守位点×2；失配不加权）\n",
    "      - -1: 完全基于 kmers 的 count，不使用任何模板乘法权重\n",
    "    \"\"\"\n",
    "    # -------------- checks --------------\n",
    "    assert direction in (1, -1), \"direction must be 1 (forward) or -1 (reverse)\"\n",
    "    assert len(start_kmer) == 7, \"start_kmer must be length-7\"\n",
    "    if start_kmer_template is not None:\n",
    "        assert len(start_kmer_template) == 7, \"start_kmer_template must be length-7\"\n",
    "    if stop_sequence is not None:\n",
    "        assert len(stop_sequence) == 5, \"stop_sequence must be length-5\"\n",
    "    assert len(template_sequence) == len(template_labels), \"template_sequence and template_labels must align\"\n",
    "    assert template_weight_mode in (1, -1), \"template_weight_mode must be 1 or -1\"\n",
    "\n",
    "    # -------------- helpers --------------\n",
    "    def levenshtein(a: str, b: str) -> int:\n",
    "        la, lb = len(a), len(b)\n",
    "        if la == 0: return lb\n",
    "        if lb == 0: return la\n",
    "        prev = list(range(lb + 1)); curr = [0] * (lb + 1)\n",
    "        for i in range(1, la + 1):\n",
    "            curr[0] = i; ai = a[i - 1]\n",
    "            for j in range(1, lb + 1):\n",
    "                cost = 0 if ai == b[j - 1] else 1\n",
    "                curr[j] = min(prev[j] + 1, curr[j - 1] + 1, prev[j - 1] + cost)\n",
    "            prev, curr = curr, prev\n",
    "        return prev[lb]\n",
    "\n",
    "    def is_conserved(label) -> bool:\n",
    "        return str(label) == \"Conserved\"\n",
    "\n",
    "    def is_cdr(label) -> bool:\n",
    "        u = str(label).upper()\n",
    "        return u.startswith(\"CDR1\") or u.startswith(\"CDR2\") or u.startswith(\"CDR3\")\n",
    "\n",
    "    def build_protected_indices(labels: List[str], length: int, tail: int) -> set:\n",
    "        \"\"\"对称保护：CDR 左右各 tail 个模板位置。\"\"\"\n",
    "        prot = set()\n",
    "        for i, lab in enumerate(labels):\n",
    "            if is_cdr(lab):\n",
    "                s = max(0, i - tail)\n",
    "                e = min(length - 1, i + tail)\n",
    "                for j in range(s, e + 1):\n",
    "                    prot.add(j)\n",
    "        return prot\n",
    "\n",
    "    def find_all_positions(seq: str, sub: str) -> List[int]:\n",
    "        out, i = [], seq.find(sub, 0)\n",
    "        while i != -1:\n",
    "            out.append(i)\n",
    "            i = seq.find(sub, i + 1)\n",
    "        return out\n",
    "\n",
    "    # -------------- 黑名单：从长序列生成被禁 7-mer（I→L，仅用于黑名单；kmers 自身只有 L） --------------\n",
    "    banned7L: set = set()\n",
    "    if ban_sequences:\n",
    "        for long_seq in ban_sequences:\n",
    "            if not long_seq:\n",
    "                continue\n",
    "            sL = long_seq.upper().replace('I', 'L')\n",
    "            if len(sL) >= 7:\n",
    "                for i in range(len(sL) - 6):\n",
    "                    banned7L.add(sL[i:i+7])\n",
    "\n",
    "    def contains_banned7(seq: str) -> bool:\n",
    "        if not banned7L:\n",
    "            return False\n",
    "        s = seq.upper()\n",
    "        for i in range(0, len(s) - 6):\n",
    "            if s[i:i+7] in banned7L:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # -------------- basics --------------\n",
    "    n_template = len(template_sequence)\n",
    "    protected_idx = build_protected_indices(template_labels, n_template, cdr_tail)\n",
    "    overlap_order = [6, 5, 4]\n",
    "    overlap_priority = {6: 3, 5: 2, 4: 1}\n",
    "\n",
    "    anchor = start_kmer_template if start_kmer_template is not None else start_kmer\n",
    "    positions = find_all_positions(template_sequence, anchor)\n",
    "    if not positions:\n",
    "        return {}\n",
    "\n",
    "    # 分装一个“候选计分器”，由 template_weight_mode 控制\n",
    "    def adjust_score(cnt: int, use_template: bool, tgt_pos: int, ext_aa: str) -> int:\n",
    "        \"\"\"\n",
    "        根据模板匹配调整得分，考虑I/L等价性。\n",
    "        \"\"\"\n",
    "        if template_weight_mode == -1:\n",
    "            return cnt\n",
    "\n",
    "        # template_weight_mode == 1\n",
    "        if use_template and 0 <= tgt_pos < n_template:\n",
    "            # 获取模板上的氨基酸\n",
    "            template_aa = template_sequence[tgt_pos]\n",
    "\n",
    "            # 如果模板是 I，并且扩展氨基酸是 L，视为等价\n",
    "            if template_aa == 'I' and ext_aa == 'L':\n",
    "                template_aa = 'L'  # 将模板的 I 当作 L 来处理\n",
    "\n",
    "            # 计算得分\n",
    "            if template_aa == ext_aa:\n",
    "                return cnt * (10 if is_conserved(template_labels[tgt_pos]) else 2)\n",
    "    \n",
    "        return cnt\n",
    "\n",
    "    # -------------- 单起点搜索 --------------\n",
    "    def search_from_pos(pos: int) -> Dict[str, int]:\n",
    "        def next_ext_pos(curr_len: int) -> int:\n",
    "            added = curr_len - 7\n",
    "            return (pos + 7 + added) if direction == 1 else (pos - 1 - added)\n",
    "\n",
    "        def expand_fn(current_seq: str) -> List[Tuple[str, int, str]]:\n",
    "            tgt_pos = next_ext_pos(len(current_seq))\n",
    "            use_template = (0 <= tgt_pos < n_template)\n",
    "            cand_by_aa: Dict[str, Tuple[str, int, int]] = {}\n",
    "\n",
    "            for ov in overlap_order:\n",
    "                if ov > len(current_seq):\n",
    "                    continue\n",
    "\n",
    "                if direction == 1:\n",
    "                    anchor_sub = current_seq[-ov:]\n",
    "                    ext_idx = -1 - (6 - ov)   # 6/5/4 -> -1/-2/-3\n",
    "                    for kmer, cnt in kmers.items():\n",
    "                        # 候选级黑名单\n",
    "                        if banned7L and kmer.upper() in banned7L:\n",
    "                            continue\n",
    "                        if not kmer.startswith(anchor_sub):\n",
    "                            continue\n",
    "                        if abs(ext_idx) > len(kmer):\n",
    "                            continue\n",
    "                        ext_aa = kmer[ext_idx]\n",
    "\n",
    "                        adj = adjust_score(cnt, use_template, tgt_pos, ext_aa)\n",
    "                        pri = overlap_priority[ov]\n",
    "                        if ext_aa in cand_by_aa:\n",
    "                            _, prev_sc, prev_pri = cand_by_aa[ext_aa]\n",
    "                            if (pri > prev_pri) or (pri == prev_pri and adj > prev_sc):\n",
    "                                cand_by_aa[ext_aa] = (kmer, adj, pri)\n",
    "                        else:\n",
    "                            cand_by_aa[ext_aa] = (kmer, adj, pri)\n",
    "\n",
    "                else:\n",
    "                    anchor_sub = current_seq[:ov]\n",
    "                    for kmer, cnt in kmers.items():\n",
    "                        if banned7L and kmer.upper() in banned7L:\n",
    "                            continue\n",
    "                        if not kmer.endswith(anchor_sub):\n",
    "                            continue\n",
    "                        if len(kmer) <= ov:\n",
    "                            continue\n",
    "                        ext_idx = len(kmer) - ov - 1  # 6/5/4 -> 0/1/2\n",
    "                        if ext_idx < 0:\n",
    "                            continue\n",
    "                        ext_aa = kmer[ext_idx]\n",
    "\n",
    "                        adj = adjust_score(cnt, use_template, tgt_pos, ext_aa)\n",
    "                        pri = overlap_priority[ov]\n",
    "                        if ext_aa in cand_by_aa:\n",
    "                            _, prev_sc, prev_pri = cand_by_aa[ext_aa]\n",
    "                            if (pri > prev_pri) or (pri == prev_pri and adj > prev_sc):\n",
    "                                cand_by_aa[ext_aa] = (kmer, adj, pri)\n",
    "                        else:\n",
    "                            cand_by_aa[ext_aa] = (kmer, adj, pri)\n",
    "\n",
    "            pot = [(k, s, aa) for aa, (k, s, _) in cand_by_aa.items()]\n",
    "            pot.sort(key=lambda x: -x[1])\n",
    "            return pot[:beam_width]\n",
    "\n",
    "        frontier: List[Tuple[str, int]] = [(start_kmer, 0)]\n",
    "\n",
    "        for _ in range(max_iterations):\n",
    "            new_frontier: List[Tuple[str, int]] = []\n",
    "            for seq, sc in frontier:\n",
    "                for kmer, ext_sc, aa in expand_fn(seq):\n",
    "                    new_seq = (seq + aa) if direction == 1 else (aa + seq)\n",
    "                    new_sc  = sc + ext_sc\n",
    "\n",
    "                    # 序列级黑名单\n",
    "                    if banned7L and len(new_seq) >= 7 and contains_banned7(new_seq):\n",
    "                        continue\n",
    "\n",
    "                    # 重复 7-mer 过滤\n",
    "                    if len(new_seq) >= 7:\n",
    "                        if direction == 1:\n",
    "                            tail7 = new_seq[-7:]\n",
    "                            if tail7 in new_seq[:-7]:\n",
    "                                continue\n",
    "                        else:\n",
    "                            head7 = new_seq[:7]\n",
    "                            if head7 in new_seq[7:]:\n",
    "                                continue\n",
    "\n",
    "                    # 5-mer 终止\n",
    "                    if stop_sequence is not None and len(new_seq) >= 5:\n",
    "                        if (direction == 1 and new_seq[-5:] == stop_sequence) or \\\n",
    "                           (direction == -1 and new_seq[:5] == stop_sequence):\n",
    "                            return {new_seq: new_sc}\n",
    "\n",
    "                    # 7-mer 距离保护（模板内 & 非保护位点；是否开启由 distance_guard 控制）\n",
    "                    if distance_guard == 1:\n",
    "                        tgt_pos = next_ext_pos(len(seq))  # 新 AA 的模板坐标（扩展前长度）\n",
    "                        if (0 <= tgt_pos < n_template) and (tgt_pos not in protected_idx) and len(new_seq) >= 7:\n",
    "                            if direction == 1:\n",
    "                                q7 = new_seq[-7:]; t_start = max(0, tgt_pos - 6); t_end = tgt_pos + 1\n",
    "                            else:\n",
    "                                q7 = new_seq[:7];  t_start = tgt_pos;              t_end = min(n_template, tgt_pos + 7)\n",
    "                            templ7 = template_sequence[t_start:t_end]\n",
    "                            if len(templ7) == 7 and levenshtein(q7, templ7) >= dist_threshold:\n",
    "                                continue\n",
    "\n",
    "                    new_frontier.append((new_seq, new_sc))\n",
    "\n",
    "            if not new_frontier:\n",
    "                break\n",
    "            frontier = heapq.nlargest(beam_width, new_frontier, key=lambda x: x[1])\n",
    "\n",
    "        best = heapq.nlargest(top_n, frontier, key=lambda x: x[1])\n",
    "        return {seq: score for (seq, score) in best}\n",
    "\n",
    "    # -------------- 多起点聚合 --------------\n",
    "    aggregated: Dict[str, int] = {}\n",
    "    for p in positions:\n",
    "        sub = search_from_pos(p)\n",
    "        for s, v in sub.items():\n",
    "            if (s not in aggregated) or (v > aggregated[s]):\n",
    "                aggregated[s] = v\n",
    "\n",
    "    if not aggregated:\n",
    "        return {}\n",
    "    return dict(sorted(aggregated.items(), key=lambda x: -x[1])[:top_n])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2724ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_C(start_kmer: str,\n",
    "                  start_kmer_template: Optional[str],\n",
    "                  kmers: Dict[str, int],\n",
    "                  template_sequence: str,\n",
    "                  template_labels: List[str],\n",
    "                  beam_width: int,\n",
    "                  max_iterations: int,\n",
    "                  top_n: int = 3,\n",
    "                  dist_threshold: int = 5,\n",
    "                  cdr_tail: int = 6,\n",
    "                  stop_sequence: Optional[str] = None,\n",
    "                  direction: int = 1,\n",
    "                  distance_guard: int = 1,                    # 1=启用距离保护, -1=关闭\n",
    "                  ban_sequences: Optional[List[str]] = None,  # 长序列黑名单：I→L，再生成所有7-mer\n",
    "                  template_weight_mode: int = 1,              # 1=按模板加权；-1=仅用count，不加权\n",
    "                  min_overlap: int = 4                        # 最小 overlap（∈{4,5,6}），范围自动为 [min_overlap..6]\n",
    "                  ) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    固定 7-mer 的束搜索（自动起点定位 + 双向扩展）\n",
    "\n",
    "    关键参数：\n",
    "      - min_overlap: 设置使用的 overlap 最小值。\n",
    "          =6 -> 仅用 overlap=6\n",
    "          =5 -> 用 overlap=6,5\n",
    "          =4 -> 用 overlap=6,5,4\n",
    "\n",
    "    计数阈值（默认）：\n",
    "      - overlap=6：count ≥ 1\n",
    "      - overlap=5/4：count ≥ 2\n",
    "\n",
    "    特殊规则：\n",
    "      - 当当前步使用 ov=6 且模板坐标有效时，如果模板氨基酸 template_sequence[tgt_pos]\n",
    "        对应的扩展 AA 未出现在候选中，则强制补入一个候选（合成 kmer；count=1），随后照常进行\n",
    "        模板加权（Conserved×10，非Conserved×5）。\n",
    "\n",
    "    变更：\n",
    "      - 在模板加权（或未加权）得到 adj 分数后，**将 adj==1 的候选过滤掉**，再进行组装扩展。\n",
    "    \"\"\"\n",
    "    # -------------- checks --------------\n",
    "    assert direction in (1, -1), \"direction must be 1 (forward) or -1 (reverse)\"\n",
    "    assert len(start_kmer) == 7, \"start_kmer must be length-7\"\n",
    "    if start_kmer_template is not None:\n",
    "        assert len(start_kmer_template) == 7, \"start_kmer_template must be length-7\"\n",
    "    if stop_sequence is not None:\n",
    "        assert len(stop_sequence) == 5, \"stop_sequence must be length-5\"\n",
    "    assert len(template_sequence) == len(template_labels), \"template_sequence and template_labels must align\"\n",
    "    assert template_weight_mode in (1, -1), \"template_weight_mode must be 1 or -1\"\n",
    "    assert min_overlap in (4, 5, 6), \"min_overlap must be one of {4,5,6}\"\n",
    "\n",
    "    # -------------- helpers --------------\n",
    "    def levenshtein(a: str, b: str) -> int:\n",
    "        la, lb = len(a), len(b)\n",
    "        if la == 0: return lb\n",
    "        if lb == 0: return la\n",
    "        prev = list(range(lb + 1)); curr = [0] * (lb + 1)\n",
    "        for i in range(1, la + 1):\n",
    "            curr[0] = i; ai = a[i - 1]\n",
    "            for j in range(1, lb + 1):\n",
    "                cost = 0 if ai == b[j - 1] else 1\n",
    "                curr[j] = min(prev[j] + 1, curr[j - 1] + 1, prev[j - 1] + cost)\n",
    "            prev, curr = curr, prev\n",
    "        return prev[lb]\n",
    "\n",
    "    def is_conserved(label) -> bool:\n",
    "        return str(label) == \"Conserved\"\n",
    "\n",
    "    def is_cdr(label) -> bool:\n",
    "        u = str(label).upper()\n",
    "        return u.startswith(\"CDR1\") or u.startswith(\"CDR2\") or u.startswith(\"CDR3\")\n",
    "\n",
    "    def build_protected_indices(labels: List[str], length: int, tail: int) -> set:\n",
    "        \"\"\"对称保护：CDR 左右各 tail 个模板位置。\"\"\"\n",
    "        prot = set()\n",
    "        for i, lab in enumerate(labels):\n",
    "            if is_cdr(lab):\n",
    "                s = max(0, i - tail)\n",
    "                e = min(length - 1, i + tail)\n",
    "                for j in range(s, e + 1):\n",
    "                    prot.add(j)\n",
    "        return prot\n",
    "\n",
    "    def find_all_positions(seq: str, sub: str) -> List[int]:\n",
    "        out, i = [], seq.find(sub, 0)\n",
    "        while i != -1:\n",
    "            out.append(i)\n",
    "            i = seq.find(sub, i + 1)\n",
    "        return out\n",
    "\n",
    "    # -------------- 黑名单：从长序列生成被禁 7-mer（I→L，仅用于黑名单；kmers 自身只有 L） --------------\n",
    "    banned7L: set = set()\n",
    "    if ban_sequences:\n",
    "        for long_seq in ban_sequences:\n",
    "            if not long_seq:\n",
    "                continue\n",
    "            sL = long_seq.upper().replace('I', 'L')\n",
    "            if len(sL) >= 7:\n",
    "                for i in range(len(sL) - 6):\n",
    "                    banned7L.add(sL[i:i+7])\n",
    "\n",
    "    def contains_banned7(seq: str) -> bool:\n",
    "        if not banned7L:\n",
    "            return False\n",
    "        s = seq.upper()\n",
    "        for i in range(0, len(s) - 6):\n",
    "            if s[i:i+7] in banned7L:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # -------------- basics --------------\n",
    "    n_template = len(template_sequence)\n",
    "    protected_idx = build_protected_indices(template_labels, n_template, cdr_tail)\n",
    "\n",
    "    # 根据 min_overlap 生成 overlap 顺序（大到小）\n",
    "    overlap_order = [ov for ov in (6, 5, 4) if ov >= min_overlap]\n",
    "    # 优先级：序号越前优先级越高\n",
    "    overlap_priority = {ov: (len(overlap_order) - i) for i, ov in enumerate(overlap_order)}\n",
    "    # 最小 count 要求：6→1，其它（5/4）→2\n",
    "    min_count_by_overlap = {ov: (1 if ov == 6 else 2) for ov in overlap_order}\n",
    "\n",
    "    anchor = start_kmer_template if start_kmer_template is not None else start_kmer\n",
    "    positions = find_all_positions(template_sequence, anchor)\n",
    "    if not positions:\n",
    "        return {}\n",
    "\n",
    "    # 模板加权（与 I/L 等价）\n",
    "    def adjust_score(cnt: int, use_template: bool, tgt_pos: int, ext_aa: str) -> int:\n",
    "        if template_weight_mode == -1:\n",
    "            return cnt\n",
    "        if use_template and 0 <= tgt_pos < n_template:\n",
    "            templ_aa = template_sequence[tgt_pos]\n",
    "            templ_norm = 'L' if templ_aa in ('I', 'L') else templ_aa\n",
    "            ext_norm   = 'L' if ext_aa in ('I', 'L') else ext_aa\n",
    "            if templ_norm == ext_norm:\n",
    "                return cnt * (10 if is_conserved(template_labels[tgt_pos]) else 5)\n",
    "        return cnt\n",
    "\n",
    "    # -------------- 单起点搜索 --------------\n",
    "    def search_from_pos(pos: int) -> Dict[str, int]:\n",
    "        def next_ext_pos(curr_len: int) -> int:\n",
    "            added = curr_len - 7\n",
    "            return (pos + 7 + added) if direction == 1 else (pos - 1 - added)\n",
    "\n",
    "        def expand_fn(current_seq: str) -> List[Tuple[str, int, str]]:\n",
    "            tgt_pos = next_ext_pos(len(current_seq))\n",
    "            use_template = (0 <= tgt_pos < n_template)\n",
    "            cand_by_aa: Dict[str, Tuple[str, int, int]] = {}\n",
    "\n",
    "            for ov in overlap_order:\n",
    "                if ov > len(current_seq):\n",
    "                    continue\n",
    "\n",
    "                if direction == 1:\n",
    "                    anchor_sub = current_seq[-ov:]\n",
    "                    ext_idx = -1 - (6 - ov)   # ov=6/5/4 -> -1/-2/-3\n",
    "                    for kmer, cnt in kmers.items():\n",
    "                        if banned7L and kmer.upper() in banned7L:\n",
    "                            continue\n",
    "                        if not kmer.startswith(anchor_sub):\n",
    "                            continue\n",
    "                        if cnt < min_count_by_overlap[ov]:\n",
    "                            continue\n",
    "                        if abs(ext_idx) > len(kmer):\n",
    "                            continue\n",
    "                        ext_aa = kmer[ext_idx]\n",
    "\n",
    "                        adj = adjust_score(cnt, use_template, tgt_pos, ext_aa)\n",
    "                        # —— 过滤：加权后 adj==1 的候选直接丢弃 —\n",
    "                        if adj == 1:\n",
    "                            continue\n",
    "\n",
    "                        pri = overlap_priority[ov]\n",
    "                        if ext_aa in cand_by_aa:\n",
    "                            _, prev_sc, prev_pri = cand_by_aa[ext_aa]\n",
    "                            if (pri > prev_pri) or (pri == prev_pri and adj > prev_sc):\n",
    "                                cand_by_aa[ext_aa] = (kmer, adj, pri)\n",
    "                        else:\n",
    "                            cand_by_aa[ext_aa] = (kmer, adj, pri)\n",
    "\n",
    "                    # ★ ov=6 时，若模板AA不在候选中则补入一个合成候选（count=1）\n",
    "                    if 6 in overlap_order and ov == 6 and use_template:\n",
    "                        templ_aa = template_sequence[tgt_pos]\n",
    "                        if templ_aa not in cand_by_aa:\n",
    "                            synthetic_kmer = anchor_sub + templ_aa\n",
    "                            if not (banned7L and synthetic_kmer.upper() in banned7L):\n",
    "                                adj = adjust_score(1, use_template, tgt_pos, templ_aa)\n",
    "                                # 同样应用过滤\n",
    "                                if adj != 1:\n",
    "                                    pri = overlap_priority[6]\n",
    "                                    cand_by_aa[templ_aa] = (synthetic_kmer, adj, pri)\n",
    "\n",
    "                else:\n",
    "                    anchor_sub = current_seq[:ov]\n",
    "                    for kmer, cnt in kmers.items():\n",
    "                        if banned7L and kmer.upper() in banned7L:\n",
    "                            continue\n",
    "                        if not kmer.endswith(anchor_sub):\n",
    "                            continue\n",
    "                        if len(kmer) <= ov:\n",
    "                            continue\n",
    "                        if cnt < min_count_by_overlap[ov]:\n",
    "                            continue\n",
    "                        ext_idx = len(kmer) - ov - 1  # 6/5/4 -> 0/1/2\n",
    "                        if ext_idx < 0:\n",
    "                            continue\n",
    "                        ext_aa = kmer[ext_idx]\n",
    "\n",
    "                        adj = adjust_score(cnt, use_template, tgt_pos, ext_aa)\n",
    "                        # —— 过滤：加权后 adj==1 的候选直接丢弃 —\n",
    "                        if adj == 1:\n",
    "                            continue\n",
    "\n",
    "                        pri = overlap_priority[ov]\n",
    "                        if ext_aa in cand_by_aa:\n",
    "                            _, prev_sc, prev_pri = cand_by_aa[ext_aa]\n",
    "                            if (pri > prev_pri) or (pri == prev_pri and adj > prev_sc):\n",
    "                                cand_by_aa[ext_aa] = (kmer, adj, pri)\n",
    "                        else:\n",
    "                            cand_by_aa[ext_aa] = (kmer, adj, pri)\n",
    "\n",
    "                    # ★ ov=6 时补模板AA（反向）\n",
    "                    if 6 in overlap_order and ov == 6 and use_template:\n",
    "                        templ_aa = template_sequence[tgt_pos]\n",
    "                        if templ_aa not in cand_by_aa:\n",
    "                            synthetic_kmer = templ_aa + anchor_sub\n",
    "                            if not (banned7L and synthetic_kmer.upper() in banned7L):\n",
    "                                adj = adjust_score(1, use_template, tgt_pos, templ_aa)\n",
    "                                if adj != 1:\n",
    "                                    pri = overlap_priority[6]\n",
    "                                    cand_by_aa[templ_aa] = (synthetic_kmer, adj, pri)\n",
    "\n",
    "            pot = [(k, s, aa) for aa, (k, s, _) in cand_by_aa.items()]\n",
    "            pot.sort(key=lambda x: -x[1])\n",
    "            return pot[:beam_width]\n",
    "\n",
    "        frontier: List[Tuple[str, int]] = [(start_kmer, 0)]\n",
    "\n",
    "        for _ in range(max_iterations):\n",
    "            new_frontier: List[Tuple[str, int]] = []\n",
    "            for seq, sc in frontier:\n",
    "                for kmer, ext_sc, aa in expand_fn(seq):\n",
    "                    new_seq = (seq + aa) if direction == 1 else (aa + seq)\n",
    "                    new_sc  = sc + ext_sc\n",
    "\n",
    "                    # 序列级黑名单\n",
    "                    if banned7L and len(new_seq) >= 7 and contains_banned7(new_seq):\n",
    "                        continue\n",
    "\n",
    "                    # 重复 7-mer 过滤\n",
    "                    if len(new_seq) >= 7:\n",
    "                        if direction == 1:\n",
    "                            tail7 = new_seq[-7:]\n",
    "                            if tail7 in new_seq[:-7]:\n",
    "                                continue\n",
    "                        else:\n",
    "                            head7 = new_seq[:7]\n",
    "                            if head7 in new_seq[7:]:\n",
    "                                continue\n",
    "\n",
    "                    # 5-mer 终止\n",
    "                    if stop_sequence is not None and len(new_seq) >= 5:\n",
    "                        if (direction == 1 and new_seq[-5:] == stop_sequence) or \\\n",
    "                           (direction == -1 and new_seq[:5] == stop_sequence):\n",
    "                            return {new_seq: new_sc}\n",
    "\n",
    "                    # 7-mer 距离保护（模板内 & 非保护位点）\n",
    "                    if distance_guard == 1:\n",
    "                        tgt_pos = (pos + len(new_seq)) if direction == 1 else (pos - len(new_seq) + 6)\n",
    "                        if (0 <= tgt_pos < n_template) and (tgt_pos not in protected_idx) and len(new_seq) >= 7:\n",
    "                            if direction == 1:\n",
    "                                q7 = new_seq[-7:]; t_start = max(0, tgt_pos - 6); t_end = tgt_pos + 1\n",
    "                            else:\n",
    "                                q7 = new_seq[:7];  t_start = tgt_pos;              t_end = min(n_template, tgt_pos + 7)\n",
    "                            templ7 = template_sequence[t_start:t_end]\n",
    "                            if len(templ7) == 7 and levenshtein(q7, templ7) >= dist_threshold:\n",
    "                                continue\n",
    "\n",
    "                    new_frontier.append((new_seq, new_sc))\n",
    "\n",
    "            if not new_frontier:\n",
    "                break\n",
    "            frontier = heapq.nlargest(beam_width, new_frontier, key=lambda x: x[1])\n",
    "\n",
    "        best = heapq.nlargest(top_n, frontier, key=lambda x: x[1])\n",
    "        return {seq: score for (seq, score) in best}\n",
    "\n",
    "    # -------------- 多起点聚合 --------------\n",
    "    aggregated: Dict[str, int] = {}\n",
    "    for p in positions:\n",
    "        sub = search_from_pos(p)\n",
    "        for s, v in sub.items():\n",
    "            if (s not in aggregated) or (v > aggregated[s]):\n",
    "                aggregated[s] = v\n",
    "\n",
    "    if not aggregated:\n",
    "        return {}\n",
    "    return dict(sorted(aggregated.items(), key=lambda x: -x[1])[:top_n])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bd1c272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import Levenshtein\n",
    "import time\n",
    "\n",
    "def suffix_prefix_intersect(s1: str, s2: str) -> str:\n",
    "    \"\"\"返回 s1 的后缀 与 s2 的前缀 的最长交集；无交集返回空串\"\"\"\n",
    "    k = min(len(s1), len(s2))\n",
    "    while k > 0 and s1[-k:] != s2[:k]:\n",
    "        k -= 1\n",
    "    return s2[:k]  # 或者返回 s1[-k:]\n",
    "\n",
    "def normalize(seq: str) -> str:\n",
    "    \"\"\"将 I/L 视为等价：统一把 I 映射为 L。\"\"\"\n",
    "    if not isinstance(seq, str):\n",
    "        seq = str(seq)\n",
    "    return seq.replace('I', 'L')\n",
    "\n",
    "def get_candidates(query_sequence, kmer_set, max_distance=3, max_overlap=3, conserved_positions=None):\n",
    "    \"\"\"\n",
    "    获取符合条件的候选序列，包括最大距离和最大重叠。\n",
    "    conserved_positions：保守位点的列表，候选的 k-mer 在这些位置的氨基酸必须与 query_sequence 匹配。\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "    q_norm = normalize(query_sequence)\n",
    "\n",
    "    # 如果没有提供保守位点，设为 None\n",
    "    if conserved_positions is None:\n",
    "        conserved_positions = []\n",
    "\n",
    "    for kmer, count in kmer_set.items():\n",
    "        k_norm = normalize(kmer)\n",
    "        \n",
    "        # 检查保守位点的匹配\n",
    "        if conserved_positions:\n",
    "            for pos in conserved_positions:\n",
    "                if q_norm[pos] != k_norm[pos]:  # 保守位点位置不匹配\n",
    "                    break\n",
    "            else:  # 如果所有保守位点匹配\n",
    "                distance = Levenshtein.distance(q_norm, k_norm)\n",
    "                if distance <= max_distance and max_overlap_count(q_norm, k_norm) <= max_overlap:\n",
    "                    candidates.append((kmer, count, distance))\n",
    "        else:\n",
    "            distance = Levenshtein.distance(q_norm, k_norm)\n",
    "            if distance <= max_distance and max_overlap_count(q_norm, k_norm) <= max_overlap:\n",
    "                candidates.append((kmer, count, distance))\n",
    "\n",
    "    # 按 count 从大到小排序\n",
    "    candidates_sorted = sorted(candidates, key=lambda x: x[1], reverse=True)\n",
    "    return candidates_sorted\n",
    "\n",
    "def max_overlap_count(seq1, seq2):\n",
    "    \"\"\"\n",
    "    计算左右对齐时的最大“相同字符”重叠数，I==L 已被归一化处理。\n",
    "    \"\"\"\n",
    "    s1 = normalize(seq1)\n",
    "    s2 = normalize(seq2)\n",
    "    len1, len2 = len(s1), len(s2)\n",
    "    max_overlap = 0\n",
    "\n",
    "    # 左对齐：s1 向右移动\n",
    "    for i in range(1, len1):\n",
    "        n = min(len1 - i, len2)\n",
    "        if n <= 0:\n",
    "            break\n",
    "        overlap = sum(1 for j in range(n) if s1[i + j] == s2[j])\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "\n",
    "    # 右对齐：s2 向右移动\n",
    "    for i in range(1, len2):\n",
    "        n = min(len2 - i, len1)\n",
    "        if n <= 0:\n",
    "            break\n",
    "        overlap = sum(1 for j in range(n) if s1[j] == s2[i + j])\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "\n",
    "    return max_overlap\n",
    "\n",
    "def get_seed(query_sequence, kmer_set, max_distance=3, max_overlap=3, conserved_positions=None):\n",
    "    \"\"\"\n",
    "    返回得分最高的 seed: (kmer, count, distance, score)\n",
    "    \"\"\"\n",
    "    candidates = get_candidates(query_sequence, kmer_set, max_distance, max_overlap, conserved_positions)\n",
    "    if not candidates:\n",
    "        return None\n",
    "\n",
    "    best = None\n",
    "    best_score = float(\"-inf\")\n",
    "    for kmer, count, distance in candidates:\n",
    "        score = count * (2 ** (3 - distance))\n",
    "        if score > best_score:\n",
    "            best = [kmer, score]\n",
    "            best_score = score\n",
    "\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bb2b2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modified_template(template: str, target: str, placeholder: str = 'X') -> str:\n",
    "    \"\"\"\n",
    "    在只允许“一段连续插入或删除”的前提下，将 template 的长度调整为与 target 一致，\n",
    "    并选择使标准 Levenshtein（插入/删除/替换代价=1，完全相等才算匹配）距离最小的位置。\n",
    "    若 target 更长：在 template 中插入 placeholder * n；\n",
    "    若 target 更短：从 template 删除一段长度 n；\n",
    "    若两者等长：直接返回 template（不改字符差异）。\n",
    "    \"\"\"\n",
    "\n",
    "    def lev(a: str, b: str) -> int:\n",
    "        # 标准 Levenshtein 距离（无任何等价字符规则）\n",
    "        if len(a) < len(b):\n",
    "            a, b = b, a\n",
    "        if not b:\n",
    "            return len(a)\n",
    "        prev = list(range(len(b) + 1))\n",
    "        for i, ca in enumerate(a, 1):\n",
    "            curr = [i]\n",
    "            for j, cb in enumerate(b, 1):\n",
    "                cost_sub = 0 if ca == cb else 1\n",
    "                curr.append(min(\n",
    "                    prev[j] + 1,        # 删除 a 的一个字符\n",
    "                    curr[j - 1] + 1,    # 向 a 插入一个字符\n",
    "                    prev[j - 1] + cost_sub  # 替换/匹配\n",
    "                ))\n",
    "            prev = curr\n",
    "        return prev[-1]\n",
    "\n",
    "    len_t, len_g = len(template), len(target)\n",
    "    if len_t == len_g:\n",
    "        return template\n",
    "\n",
    "    if len_g > len_t:\n",
    "        # 需要在 template 插入 n 个占位符\n",
    "        n = len_g - len_t\n",
    "        best_i, best_d = 0, float('inf')\n",
    "        # 在 target 中“假删去”长度 n 的一段，找与 template 距离最小的位置\n",
    "        for i in range(len_g - n + 1):\n",
    "            cand = target[:i] + target[i + n:]\n",
    "            d = lev(cand, template)\n",
    "            if d < best_d:\n",
    "                best_d, best_i = d, i\n",
    "        insert_pos = min(best_i, len_t)\n",
    "        return template[:insert_pos] + (placeholder * n) + template[insert_pos:]\n",
    "    else:\n",
    "        # 需要从 template 删除 n 个字符（连续一段）\n",
    "        n = len_t - len_g\n",
    "        best_i, best_d = 0, float('inf')\n",
    "        for i in range(len_t - n + 1):\n",
    "            cand = template[:i] + template[i + n:]\n",
    "            d = lev(cand, target)\n",
    "            if d < best_d:\n",
    "                best_d, best_i = d, i\n",
    "        return template[:best_i] + template[best_i + n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a947d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_cdr_in_template(\n",
    "    template: Dict[str, Dict[str, Tuple[str, List[str]]]],\n",
    "    new_cdr_seq: str,\n",
    "    chain: str = \"light\",   # \"light\" 或 \"heavy\"\n",
    "    region: str = \"V\",      # \"V\" 或 \"J\"\n",
    "    cdr_tag: str = \"CDR1\"   # \"CDR1\" / \"CDR2\" / \"CDR3\"\n",
    ") -> Dict[str, Dict[str, Tuple[str, List[str]]]]:\n",
    "    \"\"\"\n",
    "    仅替换 template[chain][region] 中标记为 cdr_tag 的区域为 new_cdr_seq，\n",
    "    并同步更新 labels；不做任何 cdr_info 重算。\n",
    "    说明：若该标签在该段有多个不相邻块，会把它们的整体跨度（第一个块起点到最后一个块终点）\n",
    "          合并为一段后进行替换。\n",
    "    \"\"\"\n",
    "    # 1) 取段\n",
    "    if chain not in template or region not in template[chain]:\n",
    "        raise KeyError(f\"template 中不存在 {chain}.{region} 段\")\n",
    "    seq, labels = template[chain][region]\n",
    "    if len(seq) != len(labels):\n",
    "        raise ValueError(f\"{chain}.{region} 序列与标签长度不一致: len(seq)={len(seq)} len(labels)={len(labels)}\")\n",
    "\n",
    "    # 2) 找到 cdr_tag 的连续区间（使用你模块里的 _contiguous_ranges）\n",
    "    ranges = _contiguous_ranges(labels, cdr_tag)\n",
    "    if not ranges:\n",
    "        raise ValueError(f\"{chain}.{region} 段未找到 {cdr_tag}\")\n",
    "\n",
    "    s, e = ranges[0][0], ranges[-1][1]\n",
    "\n",
    "    # 3) 规范新序列并替换\n",
    "    new_cdr = re.sub(r\"\\s+\", \"\", new_cdr_seq).upper()\n",
    "    new_seq    = seq[:s] + new_cdr + seq[e+1:]\n",
    "    new_labels = labels[:s] + [cdr_tag] * len(new_cdr) + labels[e+1:]\n",
    "\n",
    "    # 4) 写回\n",
    "    template[chain][region] = (new_seq, new_labels)\n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9789fb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVVMTQSPASLSVSPGERATLSCRARASLGLSTDLAWYQQRPGQAPRLLLYGASTRATGLPARFSGSGSGTEFTLTLSSLQSEDSAVYYCQQYSNWPLTFGGGTKVELKRTVAAPSVFLFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDSALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRGEC\n",
      "216\n"
     ]
    }
   ],
   "source": [
    "HC_assembly = ''\n",
    "LC_assembly = ''\n",
    "file_path = 'E:/Data/Fusion/dataset/mAbs/human/SA58/casanovo/50-cleaned/kmer_50_Casanovo.csv'\n",
    "kmer_set = read_kmer_set_from_csv(file_path)\n",
    "\n",
    "#轻链\n",
    "template_sequence, template_labels = template['light']['V']\n",
    "conser_position = [i for i in range(len(template_labels)) if template_labels[i] == 'Conserved']\n",
    "start_query_sequence = template_sequence[0:7]\n",
    "start_kmer = get_seed(start_query_sequence, kmer_set, max_distance=3, max_overlap=4, conserved_positions=None)[0]\n",
    "start_kmer_template = template_sequence[0:7]\n",
    "end_query_sequence = template_sequence[(conser_position[0]-6):(conser_position[0]+1)]\n",
    "seed = get_seed(end_query_sequence, kmer_set,\n",
    "                max_distance=2, max_overlap=5, conserved_positions=[6])\n",
    "\n",
    "ban_seqs = [template['light']['C'][0], template['heavy']['C'][0]]\n",
    "if seed is None:\n",
    "    result = beam_search(start_kmer, start_kmer_template, kmer_set, template_sequence, template_labels, beam_width=5, max_iterations=conser_position[0]-6, top_n = 5, direction=1,distance_guard=1, ban_sequences=ban_seqs, template_weight_mode=1)\n",
    "    seq = next(iter(result))\n",
    "    if seq[-1] == template_sequence[conser_position[0]]:\n",
    "        LC_assembly = seq\n",
    "    else:\n",
    "        print('check the template information and kmers')  \n",
    "else:\n",
    "    end_kmer = seed[0] \n",
    "    result = beam_search(start_kmer, start_kmer_template, kmer_set, template_sequence, template_labels, beam_width=5, max_iterations=conser_position[0]-6, top_n = 5, stop_sequence=end_kmer[2:],direction=1,distance_guard=1,ban_sequences=ban_seqs, template_weight_mode=1)\n",
    "    seq = next(iter(result))\n",
    "    LC_assembly = seq\n",
    "\n",
    "query_sequence = cdr_info['light']['CDR1']['following7_seq']\n",
    "start_kmer = get_seed(query_sequence, kmer_set, max_distance=3, max_overlap=4, conserved_positions=None)[0]\n",
    "idx = cdr_info['light']['CDR1']['following7_range'][1]-6\n",
    "result = beam_search(start_kmer, query_sequence, kmer_set, template_sequence, template_labels, beam_width=1, max_iterations=idx, top_n = 5, direction=-1,distance_guard=-1, ban_sequences=ban_seqs, template_weight_mode=-1)\n",
    "seq = next(iter(result))\n",
    "Len = len(suffix_prefix_intersect(LC_assembly, seq))\n",
    "if Len>=1:\n",
    "    LC_assembly = LC_assembly+seq[Len:]\n",
    "    CDR1 = seq[Len+3:len(seq)-7]\n",
    "\n",
    "if len(CDR1) != len(cdr_info['light']['CDR1']['sequence']):\n",
    "    new_cdr1_LV = get_modified_template(cdr_info['light']['CDR1']['sequence'],CDR1)  \n",
    "    template = replace_cdr_in_template(template, new_cdr1_LV, chain=\"light\", region=\"V\", cdr_tag=\"CDR1\")\n",
    "    template_sequence, template_labels = template['light']['V']\n",
    "    conser_position = [i for i in range(len(template_labels)) if template_labels[i] == 'Conserved']\n",
    "\n",
    "\n",
    "start_kmer = LC_assembly[-7:]\n",
    "start_kmer_template = cdr_info['light']['CDR1']['following7_seq']\n",
    "end_query_sequence = template_sequence[(conser_position[2]-6):(conser_position[2]+1)]\n",
    "seed = get_seed(end_query_sequence, kmer_set,\n",
    "                max_distance=2, max_overlap=5, conserved_positions=[6])\n",
    "end_kmer = seed[0] \n",
    "result = beam_search(start_kmer, start_kmer_template, kmer_set, template_sequence, template_labels, beam_width=5, max_iterations=conser_position[2]-len(LC_assembly)+1, top_n = 5, stop_sequence=end_kmer[2:],direction=1,distance_guard=1,ban_sequences=ban_seqs, template_weight_mode=1)\n",
    "seq = next(iter(result))\n",
    "LC_assembly = LC_assembly+seq[7:]\n",
    "\n",
    "\n",
    "start_kmer = LC_assembly[-7:]\n",
    "start_kmer_template = template_sequence[(conser_position[2]-6):(conser_position[2]+1)]\n",
    "end_query_sequence = cdr_info['light']['CDR3']['preceding7_seq']\n",
    "seed = get_seed(end_query_sequence, kmer_set,\n",
    "                max_distance=2, max_overlap=5, conserved_positions=[6])\n",
    "end_kmer = seed[0] \n",
    "result = beam_search(start_kmer, start_kmer_template, kmer_set, template_sequence, template_labels, beam_width=5, max_iterations=conser_position[3]-len(LC_assembly)+1, top_n = 5, stop_sequence=end_kmer[2:],direction=1,distance_guard=1,ban_sequences=ban_seqs, template_weight_mode=1)\n",
    "seq = next(iter(result))\n",
    "LC_assembly = LC_assembly+seq[7:]\n",
    "\n",
    "start_kmer = LC_assembly[-7:]\n",
    "start_kmer_template = cdr_info['light']['CDR3']['preceding7_seq']\n",
    "end_query_sequence = cdr_info['light']['CDR3']['following7_seq']\n",
    "seed = get_seed(end_query_sequence, kmer_set,\n",
    "                max_distance=2, max_overlap=5, conserved_positions=[0,1,3])\n",
    "end_kmer = seed[0] \n",
    "result = beam_search(start_kmer, start_kmer_template, kmer_set, template_sequence, template_labels, beam_width=5, max_iterations=len(LC_assembly)+30, top_n = 5, stop_sequence=end_kmer[2:],direction=1,distance_guard=1,ban_sequences=ban_seqs, template_weight_mode=1)\n",
    "seq = next(iter(result))\n",
    "if end_kmer in seq:\n",
    "    Len = len(seq) - len(end_kmer) - len(start_kmer)\n",
    "    CDR3 = seq[7:len(seq)-7]\n",
    "    LC_assembly = LC_assembly+seq[7:]\n",
    "\n",
    "if len(CDR3) != len(cdr_info['light']['CDR3']['sequence']):\n",
    "    new_cdr3_LV = get_modified_template(cdr_info['light']['CDR3']['sequence'],CDR3)  \n",
    "    template = replace_cdr_in_template(template, new_cdr3_LV, chain=\"light\", region=\"V\", cdr_tag=\"CDR3\")\n",
    "    template_sequence, template_labels = template['light']['V']\n",
    "    conser_position = [i for i in range(len(template_labels)) if template_labels[i] == 'Conserved']\n",
    "    seq, labels = template['light']['J']\n",
    "    seq_no_cdr3 = ''.join(aa for aa, lab in zip(seq, labels) if lab != 'CDR3')\n",
    "    label_no_cdr3 = [lab for lab in labels if lab != 'CDR3']\n",
    "    template['light']['V_J'] = ( template['light']['V'][0]+seq_no_cdr3, template['light']['V'][1]+label_no_cdr3)\n",
    "else:\n",
    "    template['light']['V_J'] = ( template['light']['V'][0]+template['light']['J'][0], template['light']['V'][1]+template['light']['J'][1])\n",
    "\n",
    "\n",
    "template_sequence, template_labels = template['light']['V_J']\n",
    "start_kmer = LC_assembly[-7:]\n",
    "start_kmer_template = cdr_info['light']['CDR3']['following7_seq']\n",
    "result = beam_search(start_kmer, start_kmer_template, kmer_set, template_sequence, template_labels, beam_width=5, max_iterations=len(template_sequence) - len(LC_assembly), top_n = 5,direction=1,distance_guard=1,ban_sequences=ban_seqs, template_weight_mode=1)\n",
    "seq = next(iter(result))\n",
    "LC_assembly = LC_assembly+seq[7:]\n",
    "\n",
    "start_kmer = LC_assembly[-7:]\n",
    "start_kmer_template = template['light']['J'][0][-7:]\n",
    "template_sequence = template['light']['V_J'][0] + template['light']['C'][0]\n",
    "template_labels = template['light']['V_J'][1] + template['light']['C'][1]\n",
    "#ban_seqs = [template['heavy']['C'][0]]\n",
    "#result = beam_search_C(start_kmer, start_kmer_template, kmer_set, template_sequence, template_labels, beam_width=5, max_iterations=len(template['light']['C'][0]), top_n = 5,direction=1,distance_guard=1,ban_sequences=ban_seqs, template_weight_mode=1,min_overlap=5)\n",
    "result = beam_search_C(start_kmer, start_kmer_template, kmer_set, template_sequence, template_labels, beam_width=5, max_iterations=len(template['light']['C'][0]), top_n = 5,direction=1,distance_guard=1, template_weight_mode=1,min_overlap=5)\n",
    "seq = next(iter(result))\n",
    "if len(seq)-7 == len(template['light']['C'][0]):\n",
    "    LC_assembly = LC_assembly+seq[7:]\n",
    "    LC_template = template['light']['V_J'][0] + template['light']['C'][0]\n",
    "    LC_label = template['light']['V_J'][1] + template['light']['C'][1]\n",
    "\n",
    "print(LC_assembly)\n",
    "print(len(LC_assembly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8769c845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QVQLAQSGSELRKPGASVKVSCDTSGHSFTSNALHWVRQAPGQGLEWMGWVNTDTGTPTYAQGFTGRFVFSLDTSARTAYLQLSSLKADDTAVFYCARERDYSDYFFDYWGQGTLVTVSSASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYLCNVNHKPSNTKVDKKVEPKSCDKTHTCPPCPAPELLGGPSVFLFPPKPKDTLMLSRTPEVTCVVVDVSHEDPEVKFNWYVDGVEVHNAKTKPREEQYNSTYRVVSVLTVLHQDWLNGKEYKCKVSNKALPAPLEKTLSKAKGQPREPQVYTLPPSRDELTKNQVSLTCLVKGFYPSDLAVEWESNGQPENNYKTTPPVLDSDGSFFLYSKLTVDKSRWQQGNVFSCSVMHEALHNHYTQKSLSLSPGK\n",
      "450\n"
     ]
    }
   ],
   "source": [
    "#重链\n",
    "template_sequence, template_labels = template['heavy']['V']\n",
    "conser_position = [i for i in range(len(template_labels)) if template_labels[i] == 'Conserved']\n",
    "start_query_sequence = template_sequence[0:7]\n",
    "start_kmer = get_seed(start_query_sequence, kmer_set, max_distance=3, max_overlap=4, conserved_positions=None)[0]\n",
    "start_kmer_template = template_sequence[0:7]\n",
    "end_query_sequence = template_sequence[(conser_position[0]-6):(conser_position[0]+1)]\n",
    "seed = get_seed(end_query_sequence, kmer_set,\n",
    "                max_distance=2, max_overlap=5, conserved_positions=[6])\n",
    "\n",
    "ban_seqs = [template['light']['C'][0], template['heavy']['C'][0]]\n",
    "if seed is None:\n",
    "    result = beam_search(start_kmer, start_kmer_template, kmer_set, template_sequence, template_labels, beam_width=5, max_iterations=conser_position[0]-6, top_n = 5, direction=1,distance_guard=1, ban_sequences=ban_seqs, template_weight_mode=1)\n",
    "    seq = next(iter(result))\n",
    "    if seq[-1] == template_sequence[conser_position[0]]:\n",
    "        HC_assembly = seq\n",
    "    else:\n",
    "        print('check the template information and kmers')  \n",
    "else:\n",
    "    end_kmer = seed[0] \n",
    "    result = beam_search(start_kmer, start_kmer_template, kmer_set, template_sequence, template_labels, beam_width=5, max_iterations=conser_position[0]-6, top_n = 5, stop_sequence=end_kmer[2:],direction=1,distance_guard=1,ban_sequences=ban_seqs, template_weight_mode=1)\n",
    "    seq = next(iter(result))\n",
    "    HC_assembly = seq\n",
    "\n",
    "\n",
    "query_sequence = cdr_info['heavy']['CDR1']['following7_seq']\n",
    "start_kmer = get_seed(query_sequence, kmer_set, max_distance=3, max_overlap=4, conserved_positions=None)[0]\n",
    "idx = cdr_info['heavy']['CDR1']['following7_range'][1]-6\n",
    "result = beam_search(start_kmer, query_sequence, kmer_set, template_sequence, template_labels, beam_width=1, max_iterations=idx, top_n = 5, direction=-1,distance_guard=-1, ban_sequences=ban_seqs, template_weight_mode=-1)\n",
    "seq = next(iter(result))\n",
    "Len = len(suffix_prefix_intersect(HC_assembly, seq))\n",
    "if Len>=1:\n",
    "    HC_assembly = HC_assembly+seq[Len:]\n",
    "    CDR1 = seq[Len+3:len(seq)-7]\n",
    "\n",
    "if len(CDR1) != len(cdr_info['heavy']['CDR1']['sequence']):\n",
    "    new_cdr1_HV = get_modified_template(cdr_info['heavy']['CDR1']['sequence'],CDR1)  \n",
    "    template = replace_cdr_in_template(template, new_cdr1_HV, chain=\"heavy\", region=\"V\", cdr_tag=\"CDR1\")\n",
    "    template_sequence, template_labels = template['heavy']['V']\n",
    "    conser_position = [i for i in range(len(template_labels)) if template_labels[i] == 'Conserved']\n",
    "\n",
    "start_kmer_template = cdr_info['heavy']['CDR1']['following7_seq']\n",
    "start_kmer = HC_assembly[-7:]\n",
    "end_query_sequence = cdr_info['heavy']['CDR2']['preceding7_seq']\n",
    "seed = get_seed(end_query_sequence, kmer_set,\n",
    "                max_distance=2, max_overlap=5, conserved_positions=[6])\n",
    "if seed:\n",
    "    end_kmer = seed[0] \n",
    "    result = beam_search(start_kmer, start_kmer_template, kmer_set, template_sequence, template_labels, beam_width=5, max_iterations=100, top_n = 5, stop_sequence=end_kmer[2:],direction=1,distance_guard=1,ban_sequences=ban_seqs, template_weight_mode=1)\n",
    "    seq = next(iter(result))\n",
    "    HC_assembly = HC_assembly+seq[7:]\n",
    "\n",
    "\n",
    "start_query_sequence = cdr_info['heavy']['CDR2']['preceding7_seq']\n",
    "start_kmer = get_seed(start_query_sequence, kmer_set, max_distance=3, max_overlap=4, conserved_positions=None)[0]\n",
    "start_kmer_template = start_query_sequence\n",
    "end_query_sequence = cdr_info['heavy']['CDR2']['following7_seq']\n",
    "seed = get_seed(end_query_sequence, kmer_set,\n",
    "                max_distance=2, max_overlap=5, conserved_positions=[6])\n",
    "if seed:\n",
    "    end_kmer = seed[0] \n",
    "    result = beam_search(start_kmer, start_kmer_template, kmer_set, template_sequence, template_labels, beam_width=5, max_iterations=100, top_n = 5, stop_sequence=end_kmer[2:],direction=1,distance_guard=1,ban_sequences=ban_seqs, template_weight_mode=1)\n",
    "    seq = next(iter(result))\n",
    "    HC_assembly = HC_assembly+seq[7:]\n",
    "    CDR2 = seq[7:-7]\n",
    "if len(CDR2) != len(cdr_info['heavy']['CDR2']['sequence']):\n",
    "    new_cdr2_HV = get_modified_template(cdr_info['heavy']['CDR2']['sequence'],CDR2)  \n",
    "    template = replace_cdr_in_template(template, new_cdr2_HV, chain=\"heavy\", region=\"V\", cdr_tag=\"CDR2\")\n",
    "    template_sequence, template_labels = template['heavy']['V']\n",
    "    conser_position = [i for i in range(len(template_labels)) if template_labels[i] == 'Conserved']\n",
    "\n",
    "\n",
    "start_kmer = HC_assembly[-7:]\n",
    "start_kmer_template = cdr_info['heavy']['CDR2']['following7_seq']\n",
    "end_query_sequence = template_sequence[(conser_position[2]-6):(conser_position[2]+1)]\n",
    "seed = get_seed(end_query_sequence, kmer_set,\n",
    "                max_distance=2, max_overlap=5, conserved_positions=[6])\n",
    "end_kmer = seed[0] \n",
    "result = beam_search(start_kmer, start_kmer_template, kmer_set, template_sequence, template_labels, beam_width=5, max_iterations=conser_position[2]-len(HC_assembly)+1, top_n = 5, stop_sequence=end_kmer[2:],direction=1,distance_guard=1,ban_sequences=ban_seqs, template_weight_mode=1)\n",
    "seq = next(iter(result))\n",
    "HC_assembly = HC_assembly+seq[7:]\n",
    "\n",
    "\n",
    "start_kmer = HC_assembly[-7:]\n",
    "start_kmer_template = template_sequence[(conser_position[2]-6):(conser_position[2]+1)]\n",
    "end_query_sequence = cdr_info['heavy']['CDR3']['preceding7_seq']\n",
    "seed = get_seed(end_query_sequence, kmer_set,\n",
    "                max_distance=2, max_overlap=5, conserved_positions=[6])\n",
    "end_kmer = seed[0] \n",
    "result = beam_search(start_kmer, start_kmer_template, kmer_set, template_sequence, template_labels, beam_width=5, max_iterations=conser_position[3]-len(HC_assembly)+1, top_n = 5, stop_sequence=end_kmer[2:],direction=1,distance_guard=1,ban_sequences=ban_seqs, template_weight_mode=1)\n",
    "seq = next(iter(result))\n",
    "HC_assembly = HC_assembly+seq[7:]\n",
    "\n",
    "start_kmer = HC_assembly[-7:]\n",
    "start_kmer_template = cdr_info['heavy']['CDR3']['preceding7_seq']\n",
    "end_query_sequence = cdr_info['heavy']['CDR3']['following7_seq']\n",
    "seed = get_seed(end_query_sequence, kmer_set,\n",
    "                max_distance=2, max_overlap=5, conserved_positions=[0,1,3])\n",
    "end_kmer = seed[0] \n",
    "result = beam_search(start_kmer, start_kmer_template, kmer_set, template_sequence, template_labels, beam_width=5, max_iterations=len(HC_assembly)+30, top_n = 5, stop_sequence=end_kmer[2:],direction=1,distance_guard=1,ban_sequences=ban_seqs, template_weight_mode=1)\n",
    "seq = next(iter(result))\n",
    "if end_kmer in seq:\n",
    "    Len = len(seq) - len(end_kmer) - len(start_kmer)\n",
    "    CDR3 = seq[7:len(seq)-7]\n",
    "    HC_assembly = HC_assembly+seq[7:]\n",
    "\n",
    "if len(CDR3) != len(cdr_info['heavy']['CDR3']['sequence']):\n",
    "    new_cdr3_HV = get_modified_template(cdr_info['heavy']['CDR3']['sequence'],CDR3)  \n",
    "    template = replace_cdr_in_template(template, new_cdr3_HV, chain=\"heavy\", region=\"V\", cdr_tag=\"CDR3\")\n",
    "    template_sequence, template_labels = template['heavy']['V']\n",
    "    conser_position = [i for i in range(len(template_labels)) if template_labels[i] == 'Conserved']\n",
    "    seq, labels = template['heavy']['J']\n",
    "    seq_no_cdr3 = ''.join(aa for aa, lab in zip(seq, labels) if lab != 'CDR3')\n",
    "    label_no_cdr3 = [lab for lab in labels if lab != 'CDR3']\n",
    "    template['heavy']['V_J'] = ( template['heavy']['V'][0]+seq_no_cdr3, template['heavy']['V'][1]+label_no_cdr3)\n",
    "else:\n",
    "    template['heavy']['V_J'] = ( template['heavy']['V'][0]+template['heavy']['J'][0], template['heavy']['V'][1]+template['heavy']['J'][1])\n",
    "\n",
    "\n",
    "template_sequence, template_labels = template['heavy']['V_J']\n",
    "start_kmer = HC_assembly[-7:]\n",
    "start_kmer_template = cdr_info['heavy']['CDR3']['following7_seq']\n",
    "result = beam_search(start_kmer, start_kmer_template, kmer_set, template_sequence, template_labels, beam_width=5, max_iterations=len(template_sequence) - len(HC_assembly), top_n = 5,direction=1,distance_guard=1,ban_sequences=ban_seqs, template_weight_mode=1)\n",
    "seq = next(iter(result))\n",
    "HC_assembly = HC_assembly+seq[7:]\n",
    "\n",
    "\n",
    "start_kmer = HC_assembly[-7:]\n",
    "start_kmer_template = template['heavy']['J'][0][-7:]\n",
    "template_sequence = template['heavy']['V_J'][0] + template['heavy']['C'][0]\n",
    "template_labels = template['heavy']['V_J'][1] + template['heavy']['C'][1]\n",
    "result = beam_search_C(start_kmer, start_kmer_template, kmer_set, template_sequence, template_labels, beam_width=5, max_iterations=len(template['heavy']['C'][0]), top_n = 5,direction=1,distance_guard=1, template_weight_mode=1,min_overlap=6)\n",
    "seq = next(iter(result))\n",
    "if len(seq)-7 == len(template['heavy']['C'][0]):\n",
    "    HC_assembly = HC_assembly+seq[7:]\n",
    "    HC_template = template['heavy']['V_J'][0] + template['heavy']['C'][0]\n",
    "    HC_label = template['heavy']['V_J'][1] + template['heavy']['C'][1]\n",
    "\n",
    "print(HC_assembly)\n",
    "print(len(HC_assembly))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
